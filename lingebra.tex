\documentclass[a5paper,12pt]{amsbook}

\usepackage[czech]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{color}
\usepackage{svg}
\usepackage{amsmath}

\theoremstyle{definition}
\newtheorem{definition}{Definice}[chapter]
\newtheorem{example}{Příklad}[chapter]

% Book styles
\newcommand{\myscalar}[1]{#1}
\newcommand{\myvec}[1]{\mathbf{#1}}
\newcommand{\mycoord}[1]{\overrightarrow{\mathbf{#1}}}
\newcommand{\mymatrix}[1]{\mathbf{#1}}
\newcommand{\myspace}[1]{\mathbb{#1}}
\newcommand{\mymap}[1]{#1}
\newcommand{\mydual}[1]{\myspace{#1^{*}}}

\begin{document}

\title{Lineární algebra pro debily}
\author{Ondřej Stárek}
\maketitle

\tableofcontents

\chapter{Úvod}

\noindent Tento text se snaží čtenáře uvést do problematiky některé pokročilejší lineární algebry.
Je vedena pocitem autora, že pokud překročíte hranici prvního kurzu algebry (za vektorové
prostory), učitelé zapomněli učit a utápí se v nadšené záplavě písmenek a symbolů, namísto
vysvětlování souvislostí.

Text si neklade žádné nároky na matematickou přesnost. Koneckonců nenapsal ho matematik,
ale programátor, který se samostudiem pokoušel naučit něco nového. Spíše se jedná o poznámky
a popsané úvahy, které musel udělat, když se prokousával spoustou matematických textů
a pokoušel se je pochopit. Vlastně tímto textem danou látku vysvětluje především sám sobě.
Přesto si autor fandí, že pro jiné samouky by text mohl být přínosem a ulehčí jim cestu
k pochopení.

Text je určený samoukům, kteří už v současné době znají základy lineární algebry: maticové
operace, tělesa a vektorové prostory.

\chapter{Lineární zobrazení}

\section{Definice}

\noindent Lineární zobrazení je všeobecně známý pojem, obvykle probíraný již v základním kurzu
algebry. Nicméně i u něho autorovi zůstala řada nejasností. Proto se mu bude věnovat.

Co vlastně takové lineární zobrazení je? Není na tom nic složitého: jedná se
o zobrazení/transformaci/převod vektorů z jednoho vektorového prostoru do jiného. Zobrazení ovšem
není libovolné - musí zachovávat strukturu vektorového prostoru. To znamená, že pokud nějaký vektor
ve zdrojovém prostoru vynásobím skalárem, obrazem jeho násobku bude stejný násobek jeho obrazu. Pokud
sečtu dva vektory, obrazem součtu bude součet jejich obrazů. 

Pokud myšlenka stále není jasná, zkusme to na obrázku. Zde je ukázka transformace, která prodlužuje
měřítko na vodorovné ose. Na levém obrázku je původní součet dvou vektorů. Vpravo jsou všechny vektory
přetransformované. Je vidět, že vůbec nezáleží, zda vektory nejdříve sečteme, a pak transformujeme,
anebo nejdříve transformujeme, a pak sečteme.

\begin{center}
\includesvg[width=200pt]{lintrans1}
\end{center}

\noindent Požadovat po lineárním zobrazení tyto podmínky je poměrně přirozené. Díky nim cokoliv, co můžeme
prohlásit o vektorech ve zdrojovém prostoru, platí zároveň i na jejich obrazech.

Nyní víme, co bychom od lineárního zobrazení očekávali, zkusme ho tedy přesněji nadefinovat.

\begin{definition}
Mějme vektorové prostory $\myspace{V}$ a $\myspace{W}$ oba nad tělesem $\myspace{T}$ a zobrazení
$\mymap{L}: \myspace{V}\rightarrow\myspace{W}$. Zobrazení $\mymap{L}$ je linerání zobrazení právě tehdy
pokud platí:

\begin{enumerate}
  \item $\forall\myvec{x}\in\myspace{V},\forall\myscalar{\alpha}\in\myspace{T}\;
    \mymap{L}(\myscalar{\alpha}\myvec{x})=\myscalar{\alpha}L(\myvec{x})$
  \item $\forall\myvec{x},\myvec{y}\in\myspace{V}\;\mymap{L}(\myvec{x}+\myvec{y})
    =\mymap{L}(\myvec{x})+\mymap{L}(\myvec{y})$
\end{enumerate}

\end{definition}

\noindent Definice je v principu jednoduchá, ale protože ďábel tkví v detailech, probereme ji podrobněji:

\begin{itemize}
  \item povšimněte si, že oba vektorové prostory jsou nad stejným tělesem. To je nutnost, jinak bychom
    nebyli schopní obraz vektoru násobit stejným skalárem. Linerní zobrazení tedy jsou omezená pouze
    na prostory nad stejným tělesem.
  \item V zápisu jsou použité stejné značky pro sčítání vektorů a pro násobení skalárem. Ale to neznamená,
    že se vždy jedná o stejné operace. V některých případech se jedná o operace prostoru $\myspace{V}$
    a v jiném o operace prostoru $\myspace{W}$. Nechávám na čtenáři, ať si odvodí, kdy se jedná o kterou
    (nehledejte v tom žádný chyták).
  \item Obě podmínky jsou poměrně přímočaré. První říká, že lineární zobrazení zachovává operaci násobení
    skalárem, druhá, že zachovává operaci sčítání vektorů.
\end{itemize}

\noindent Přímo z definice vyplývá jedna zajímavá vlastnost: obraz nulového prvku musí být opět
nulový prvek:
\begin{align*}
\myvec{v} + \myvec{0} &= \myvec{v} \\
\mymap{L}(\myvec{v} + \myvec{0}) &= \mymap{L}(\myvec{v}) \\
\mymap{L}(\myvec{v}) + \mymap{L}(\myvec{0}) &= \mymap{L}(\myvec{v}) \\
\mymap{L}(\myvec{v}) - \mymap{L}(\myvec{v}) + \mymap{L}(\myvec{0}) 
    &= \mymap{L}(\myvec{v}) - \mymap{L}(\myvec{v}) \\
\mymap{L}(\myvec{0}) &= \myvec{0}
\end{align*}
(První řádka je z definice vektorového prostoru, další dvě řádky jsou aplikace definice
lineárního zobrazení, čtvrtá přičítá opačný vektor k obrazu vektoru $\myvec{v}$.) Důsledkem
této vlastnosti je, že posunutí (přičtení nenulového vektoru) \textbf{není} lineární zobrazení
(nulu převede na neulový vektor). To je v praxi poměrně velké omezení a matematici ho řeší
pomocí tzv. affinních zobrazení a prostorů, které si podrobněji probereme v kapitole XXX.

\begin{example}\textbf{Identita} - jedno z nejjednodušších zobrazení je takové, které převádí vektor
na ten samý:
\begin{equation*}
\mymap{L}:\,\myspace{V}\rightarrow\myspace{V}:\;\mymap{L}(\myvec{x})=\myvec{x}
\end{equation*} 
Je triviální si dokázat, že obě podmínky definice jsou zachované. Aby ne, když původní vektor
a jeho obraz jsou stejné.

Identita je zároveň ukázkou typické situace. Ačkoliv definice lineárního zobrazení pracuje se dvěma
prostory, typické použití je zobrazení do stejného prostoru, tedy kdy oba prostory jsou stejné.

\end{example}

\begin{example}\label{example:rotate}\textbf{Rotace} vektoru o nějaký úhel je dalším běžným příkladem
lineárního zobrazení:
\begin{center}
\includesvg[width=200pt]{lintrans2}
\end{center}
Rotace nemění délku vektorů, pouze ho pootočí. První podmínka tedy splněna je - nezávisí zda
vektor prodloužíme před nebo až po transformaci. Druhá podmínka je graficky také splněna - oba zdrojové
vektory i jejich součet se otočí stejně. Formální důkaz si čtenář určitě dokáže udělat sám.

\end{example}

\begin{example}\label{example:polynoms}\textbf{Substituce v polynomu}. Zkusme nyní ne úplně tradiční
vektorový prostor polynomů do řádu 3. Vektory prostoru tedy jsou funkce typu
\begin{equation*}
p(x)=ax^{3}+bx^{2}+cx+d
\end{equation*}
Operace násobení skalárem a sčítání polynomů jsou definované tak, jak jsme u polynomů zvyklí.
Nyní proveďme substituci $x=\frac{t}{2}$
\begin{equation*}
p(\frac{t}{2})=a\left(\frac{t}{2}\right)^{3}+b\left(\frac{t}{2}\right)^{2}+c\left(\frac{t}{2}\right)+d 
  = \frac{a}{8}t^{3}+\frac{b}{4}t^{2}+\frac{c}{2}t+d
\end{equation*} 
\noindent Je vidět, že výsledek substituce je opět polynom řádu 3. Tedy tato substituce funguje
jako zobrazení z našeho prostoru do našeho prostoru. Jedná se o lineární zobrazení?
\begin{enumerate}
  \item Obrazem vektoru $\alpha p(x)$ je
    \begin{equation*}
      \alpha\frac{a}{8}t^{3}+\alpha\frac{b}{4}t^{2}+\alpha\frac{c}{2}t+\alpha{}d 
      = \alpha p(\frac{t}{2})
    \end{equation*}
  \item Obrazem vektoru $p_1(x) + p_2(x)$ je
    \begin{equation*}
      \frac{a_1+a_2}{8}t^{3}+\frac{b_1+b_2}{4}t^{2}+\frac{c_1+c_2}{2}t+d_1+d_2
      = p_1(\frac{t}{2})+p_2(\frac{t}{2})
    \end{equation*}
\end{enumerate}
Obě podmínky definice lineárního zobrazení jsou zřejmě splněné, takže substituce
je lineárním zobrazením.

K čemu nám něco takového je? Například tato substituce je základem velmi elegantního algoritmu
pro kreslení křivek, který si parametrickou rovnici $p(t)=0$ pomocí této substituce rozkrájí
na drobné úseky tak, aby na každém z nich byl rozdíl mezi $p(0)$ a $p(1)$ právě jeden pixel
zobrazovacího zařízení.

\end{example}

\section{Souřadnice a báze}

\noindent Ze základního kurzu lineární algebry víme, že každý vektor nějakého vektorového prostoru lze
vyjádřit jako lineární kombinaci bázových vektorů (koeficienty lineární kombinace se nazývají
\textit{souřadnice}). Ačkoliv báze mohou být různé, počet bázových vektorů je vždy stejný
a definuje \textit{dimenzi vektorového prostoru}. Omezme se nyní na prostory s konečnou dimenzí
a zkusme zapřemýšlet o vyjádření lineárního zobrazení v souřadnicích.

Vezměme si tedy zdrojový vektorový prostor $\myspace{V}$ dimenze $n$ a jeho bázi 
$\{\myvec{b_{v_1}},\myvec{b_{v_2}},\ldots,\myvec{b_{v_n}}\}$. Stejně tak cílový
vektorový prostor $\myspace{W}$ dimenze $m$ a jeho bázi $\{\myvec{b_{w_1}}, \myvec{b_{w_2}},
\ldots,\myvec{b_{w_m}}\}$. A mějme lineární zobrazení $\mymap{L}: \myspace{V}\rightarrow\myspace{W}$
mezi nimi. Víme, že každý vektor $\myvec{v}\in\myspace{V}$ lze vyjádřit jako lineární kombinaci
\begin{equation*}
\myvec{v}=\myscalar{v_{1}}\myvec{b_{v_1}}+\myscalar{v_{2}}\myvec{b_{v_2}}+\cdots+\myscalar{v_{n}}
  \myvec{b_{v_n}}
\end{equation*} 
Pokud tento vektor použijeme jako argument lineárního zobrazení, tak za použití obou podmínek
z definice:
\begin{equation*}
\begin{split}
\myvec{w}=L(\myvec{v})&=\mymap{L}(\myscalar{v_{1}}\myvec{b_{v_1}}+\myscalar{v_{2}}\myvec{b_{v_2}}
    +\cdots+\myscalar{v_{n}}\myvec{b_{v_n}})\\
  &=\myscalar{v_{1}}\mymap{L}(\myvec{b_{v_1}})+\myscalar{v_{2}}\mymap{L}(\myvec{b_{v_2}})+\cdots
    +\myscalar{v_{n}}\mymap{L}(\myvec{b_{v_n}})
\end{split}
\end{equation*} 
Tedy obraz vektoru $\myvec{v}$ je lineární kombinace obrazů bázových vektorů.
Pokud i obrazy bázových vektorů vyjádříme v souřadnicích prostoru $\myspace{W}$, lze lineární
zobrazení zapsat pomocí maticové aritmetiky (tzn. obrazy vektorů báze v předchozí rovnici
vyjádříme jako souřadnice v prostoru $\myspace{W}$ a sčítáním po složkách získáme souřadnice
vektoru $\myvec{w}$):
\begin{equation*}
\left(\begin{array}{c}
w_{1}\\
w_{2}\\
\vdots\\
w_{m}
\end{array}\right)=\left(\begin{array}{cccc}
\mymap{L}(\myvec{b_{v_1}})_1 & \mymap{L}(\myvec{b_{v_2}})_1 & \cdots & \mymap{L}(\myvec{b_{v_n}})_1\\
\mymap{L}(\myvec{b_{v_1}})_2 & \mymap{L}(\myvec{b_{v_2}})_2 & \cdots & \mymap{L}(\myvec{b_{v_n}})_2\\
\vdots & \vdots & \ddots & \vdots\\
\mymap{L}(\myvec{b_{v_1}})_m & \mymap{L}(\myvec{b_{v_2}})_m & \cdots & \mymap{L}(\myvec{b_{v_n}})_m
\end{array}\right)\left(\begin{array}{c}
v_{1}\\
v_{2}\\
\vdots\\
v_{n}
\end{array}\right)
\end{equation*}
nebo zjednodušeně:
\begin{equation*}
\mycoord{w}=\mymatrix{L}\mycoord{v}
\end{equation*}
kde sloupce matice $\mymatrix{L}$ jsou souřadnice obrazů zdrojové báze a $\mycoord{v}$
a $\mycoord{w}$ jsou souřadnice vektorů $\myvec{v}$ a $\myvec{w}$.

\begin{example}Pokračujme v příkladu \ref{example:rotate}. Pokud vektor pootočíme o úhel $\alpha$,
situace bude vypadat takto:
\begin{center}
\includesvg[width=200pt]{rotate}
\end{center}
Souřadnice původního vektoru jsou
\begin{align*} 
x &= d\cos\beta\\ 
y &= d\sin\beta
\end{align*}
kde $d$ je délka vektoru. Souřadnice transformovaného vektoru jsou
\begin{align*} 
x' &= d\cos(\beta+\alpha) = d\cos\beta\cos\alpha - d\sin\beta\sin\alpha\\ 
y' &= d\sin(\beta+\alpha) = d\sin\beta\cos\alpha + d\cos\beta\sin\alpha
\end{align*}
Když dosadíme za $d$ z původních souřadnic dostáváme
\begin{align*} 
x' &= x\cos\alpha - y\sin\alpha\\ 
y' &= x\sin\alpha + y\cos\alpha
\end{align*}
V maticovém tvaru rotaci vyjádříme takto:
\begin{equation*}
\left(\begin{array}{cc}
\cos\alpha & -\sin\alpha\\
\sin\alpha & \cos\alpha\\
\end{array}\right)\left(\begin{array}{c}
x\\
y
\end{array}\right)=\left(\begin{array}{c}
x'\\
y'
\end{array}\right)
\end{equation*}
Transformace v této podobě je používaná například v počítačové grafice. Grafik
vytvoří model, aniž by znal jeho umístění ve scéně. Ten, kdo scénu kompletuje,
model někam umístí a otočí si ho podle potřeby.

Otočení souřadnicového systému je samozřejmě také běžná činnost ve fyzice.

\end{example}

\begin{example}Vraťme se k příkladu \ref{example:polynoms} a vezměme si jednoduchou bázi prostoru
$\{x^3, x^2, x, 1\}$, polynom $p(x)$ vyjádřený jako souřadnice je $(a, b, c, d)^T$ a matice zobrazení
vypadá takto:
\begin{equation*}
\left(\begin{array}{cccc}
\frac{1}{8} & 0 & 0 & 0\\
0 & \frac{1}{4} & 0 & 0\\
0 & 0 & \frac{1}{2} & 0\\
0 & 0 & 0 & 1
\end{array}\right)\left(\begin{array}{c}
a\\
b\\
c\\
d
\end{array}\right)=\left(\begin{array}{c}
\frac{1}{8}a\\
\frac{1}{4}b\\
\frac{1}{2}c\\
d
\end{array}\right)
\end{equation*}
Ptáte se, k čemu nám to je? Už jsem zmínil, že tato substituce je základ pro jeden
algoritmus. Jenže ouha, počítače neumí jednoduše kouknout na nějaký vzoreček a do
něho substituovat. Co ale umí skvěle, je násobit matice. Tím, že jsme polynom vyjádřili
jako souřadnice a substituci jako matici, jsme získali snadný způsob, jak algoritmus
naimplementovat.
\end{example}

Nyní víme, jak lineární zobrazení vyjádřit jako matici. Protože každý vektor lze vyjádřit
jako lineární kombinaci bázových vektorů, jsme matici schopni vytvořit vždy (skládá se ze
souřadnic obrazů zdrojové báze). Tzn. \textbf{pro každé lineární zobrazení} (stále uvažujeme
prostory s konečnou dimenzí) \textbf{existuje jeho matice}.

V knížkách algebry se už obvykle příliš nezdůrazňuje, že předchozí platí i \textbf{obráceně}, tedy 
že \textbf{každá dvourozměrná matice určuje nějaké lineární zobrazení.}

Každý vektor lze jednoznačně vyjádřit jako souřadnice. I opačně každé souřadnice odpovídají nějakému
vektoru (obsahují koeficienty lineární kombinace báze a z definice vektorového prostoru je každá
lineární kombinace vektorů opět vektor). Tudíž, pokud matici $\mymatrix{A}$ vynásobíme souřadnicemi
libovolného vektoru, získáme opět souřadnice nějakého vektoru. A protože z definice maticových
operací platí
\begin{enumerate}
  \item$
      \mymatrix{A}\left(\myscalar{\alpha}\mycoord{x}\right)=
          \myscalar{\alpha}\left(\mymatrix{A}\mycoord{x}\right)$,
  \item$
      \mymatrix{A}\left(\mycoord{x_1}+\mycoord{x_2}\right)=
          \mymatrix{A}\mycoord{x_1}+\mymatrix{A}\mycoord{x_2}$,
\end{enumerate}
jsou splněné obě podmínky definice lineárního zobrazení.

Povšiměte si, že v předchozím vůbec neříkám, o jaké konkrétní prostory se jedná. Matice tedy
určuje obecně nekonečně mnoho lineárních zobrazení mezi libovolnými vektorovými prostory dimenzí
odpovídajících rozměrům matice (samozřejmě matice i prostory musí být nad stejným tělesem).

I když se jedná o poměrně triviální fakt, jde o podstatnou myšlenkovou úvahu.
Autor měl například dlouho problém pochopit termín \textit{podobnost matic}. Matice je jenom
pole čísel, proto podobnost nedává žádný smysl, obzvláště pokud podobné matice mají zcela
rozdílná čísla. Jejich podobnost spočívá v tom, že odpovídají stejnému lineárnímu zobrazení
v různých bázích (transformace bází viz. kapitola XXX). I další pojmy algebry, například vlastní
čísla matice, dávají smysl až s tímto pozorováním. Matematici často mezi oběma pojmy tiše přechází,
což před pochopením této souvislosti samoukům, jako jsem já, způsobuje bolení hlavy.

\section{Transformace bází}

\noindent Zkusme nyní zapřemýšlet, jak je možné transformovat souřadnicové systémy.  K čemu by nám
něco takového bylo? Transformace souřadnicových systémů je důležitá pro fyziku. Platnost
fyzikálních zákonů musí být nezávislá na souřadnicích. Jednoduše řečeno Newtonovo jablko bude
pořád padat zcela stejně, bez ohledu na to, jak si zvolíme osy. Pro výpočty i měření si ovšem
nějaké zvolit musíme a musíme také být schopní číselné výsledky mezi souřadnicovými systémy
převádět.

Souřadnice vektorů jsou určené bází, tedy otázku můžeme přeformulovat na transformaci bází.
Potřebujeme tedy zjistit, jaké podmínky musí lineární zobrazení splňovat, aby transformací
báze zdrojového vektorového prostoru vznikla opět báze cílového prostoru. Je zřejmé, že ne každé
lineární zobrazení toto splňuje. Například zobrazení, které každý vektor transformuje na nulový
vektor, nedokáže vytvořit bázi, protože množina nulových vektorů není lineárně nezávislá.

Mějme tedy opět lineární zobrazení $\mymap{L}: \myspace{V}\rightarrow\myspace{W}$, kde $\myspace{V}$
a $\myspace{W}$ jsou vektorové prostory konečných dimenzí $n > 0$ a $m > 0$, a bázi prostoru $\myspace{V}$
$\{\myvec{v_1}, \myvec{v_2}, \ldots, \myvec{v_n}\}$. Jaké podmníky musí lineární zobrazení
splnit, aby množina obrazů bází $\{\mymap{L}(\myvec{v_1}), \mymap{L}(\myvec{v_2}), \ldots, 
\mymap{L}(\myvec{v_n})\}$ byla bází prostoru $\myspace{W}$? Z definice báze víme, že
\begin{enumerate}
  \item musí generovat celý prostor $\myspace{W}$
  \item a musí být lineárně nezávislá.
\end{enumerate}
Je zřejmé, že dimenze obou prostorů musí být stejné. Pokud je $n < m$, pak existuje vektor, který
obrazy bází nedokáží vygenerovat. Naopak pokud $n > m$, pak množina obrazů báze není lineárně
nezávislá.

První podmínku lze splnit poměrně snadno. Každý vektor prostoru $\myspace{W}$, který je
generovaný obrazy báze, musí být obrazem nějakého vektoru prostoru $\myspace{V}$:
\begin{equation*}
\begin{split}
\myvec{w}
  &= \myscalar{\alpha{}_1}\mymap{L}(\myvec{v_1}) + \myscalar{\alpha{}_2}\mymap{L}(\myvec{v_2})
      + \cdots + \myscalar{\alpha{}_n}\mymap{L}(\myvec{v_n}) \\
  &= \mymap{L}(\myscalar{\alpha{}_1}\myvec{v_1} + \myscalar{\alpha{}_2}\myvec{v_2} + \cdots 
      + \myscalar{\alpha{}_n}\myvec{v_n}) = \mymap{L}(\myvec{v})
\end{split}
\end{equation*}
Pokud tedy obrazy báze mají generovat celý prostor $\myspace{W}$, musí být zobrazení \textbf{na}
(stručné označení, že každý prvek prostoru $\myspace{W}$ je obrazem nějakého prvku prostoru
$\myspace{V}$). Úvaha platí i obráceně: pokud je zobrazení \textbf{na}, lze každý vektor
prostoru $\myspace{W}$ vyjádřit jako lineární kombinaci obrazů báze - každý vektor má
svůj vzor a předchozí rovnici lze aplikovat pozpátku.

Druhá podmínka je složitější. Pokud je množina obrazů báze lineárně závislá, pak existuje
nenulová lineární kombinace
\begin{equation*}
\myscalar{\alpha{}_1}\mymap{L}(\myvec{v_1}) + \myscalar{\alpha{}_2}\mymap{L}(\myvec{v_2}) 
  + \cdots + \myscalar{\alpha{}_n}\mymap{L}(\myvec{v_n}) = \myvec{0}
\end{equation*}
 Z podmínky (1) víme, že množina generuje celý prostor $\myspace{W}$, proto je
možné každý vektor $\myvec{w}\neq\myvec{0}\in\myspace{W}$ vyjádřit jako nenulovou lineární kombinaci
\begin{equation*}
\begin{split}
\myvec{w} &= \myscalar{\beta{}_1}\mymap{L}(\myvec{v_1}) + \myscalar{\beta{}_2}\mymap{L}(\myvec{v_2}) 
  + \cdots + \myscalar{\beta{}_n}\mymap{L}(\myvec{v_n}) \\
&= \mymap{L}(\myscalar{\beta{}_1}\myvec{v_1} + \myscalar{\beta{}_2}\myvec{v_2} 
  + \cdots + \myscalar{\beta{}_n}\myvec{v_n})
\end{split}
\end{equation*}
K tomuto vyjádření vektoru $\myvec{w}$ je možné libovolně přičítat první kombinaci obrazů báze
(přičítání nulového vektoru nic nezmění):
\begin{equation*}
\begin{split}
\myvec{w} + \myvec{0} &= \myscalar{\beta{}_1}\mymap{L}(\myvec{v_1}) 
  + \myscalar{\beta{}_2}\mymap{L}(\myvec{v_2}) + \cdots + \myscalar{\beta{}_n}\mymap{L}(\myvec{v_n}) \\
  &+ \myscalar{\alpha{}_1}\mymap{L}(\myvec{v_1}) + \myscalar{\alpha{}_2}\mymap{L}(\myvec{v_2}) 
  + \cdots + \myscalar{\alpha{}_n}\mymap{L}(\myvec{v_n}) \\
&= \mymap{L}((\myscalar{\beta{}_1} + \myscalar{\alpha{}_1})\myvec{v_1} 
  + (\myscalar{\beta{}_2} + \myscalar{\alpha{}_2})\myvec{v_2} 
  + \cdots + (\myscalar{\beta{}_n} + \myscalar{\alpha{}_n})\myvec{v_n})
\end{split}
\end{equation*}
Protože obě kombinace jsou nenulové, je zřejmé, že vektor $\myvec{w}$ je obrazem dvou různých
vektorů z prostoru $\myspace{V}$ (jejich souřadnice jsou rozdílné). Znamená to tedy, že
linerání zobrazení \textbf{není prosté} (stručné označení, že jeden obraz může mít více vzorů).
Tedy, pokud zobrazení \textbf{je prosté}, pak je množina obrazů báze lineárně nezávislá\footnote{
  Pokud jste se v poslední větě ztratili, jedná se o tzv. \textit{nepřímý důkaz}, kdy se
  implikace $A\Rightarrow B$ dokazuje jako $\lnot B\Rightarrow\lnot A$. Já jsem dokázal, že pokud
  množina obrazů je lineárně závislá, pak zobrazení není prosté. Tedy obráceně pokud zobrazení
  je prosté, množina je lineárně nezávislá.
}.

Získali jsme tedy dvě nutné a zároveň postačující podmínky. Lineární zobrazení, které 
je \textbf{prosté} a \textbf{na} transformuje bázi na jinou bázi a tedy slouží jako transformace
souřadnicového systému.

Otázka zní, zda je možné tvrdit i opak: každé lineární zobrazení, které transformuje bázi,
je \textbf{prosté} a \textbf{na}. I toto platí. Důkaz první podmínky jsme již udělali (vztah
mezi generováním celého prostoru a \textbf{na} jsme ukázali v obou směrech). Důkaz
druhé podmínky jde udělat podobným způsobem. Zvídavý čtenář ho jistě nalezne v podstatně
elegantnějších podobách v učebnicích algebry.

Nyní tedy víme, že lineární zobrazení \textbf{prosté} a \textbf{na} funguje jako transformace
báze. Takové zobrazení se nazývá \textit{bijekce} a má jednu fajn vlastnost: existuje pro něj
inverzní zobrazení. Je opět poměrně jednoduché si ukázat, že i inverzní zobrazení je lineární:
\begin{enumerate}
  \item $\mymap{L}^{-1}(\myscalar{\alpha}\mymap{L}(\myvec{v})) 
      = \mymap{L^{-1}}(\mymap{L}(\myscalar{\alpha}\myvec{v})) = \myscalar{\alpha}\myvec{v}$
  \item $\mymap{L}^{-1}(\mymap{L}(\myvec{v_1}) + \mymap{L}(\myvec{v_2}))
      = \mymap{L}^{-1}(\mymap{L}(\myvec{v_1} + \myvec{v_2}))
      = \myvec{v_1} + \myvec{v_2}$.
\end{enumerate}
Důsledkem je tedy fakt, že pokud přetransformuji souřadnicový systém, vždy jsem schopen
se vrátit zpět k původním souřadnicím.

Doteď jsme transformovali bázi, ale nepotřebovali jsme si žádnou zvolit. Snesme se nyní
z abstraktních výšin do praktického užití a zauvažujme o transformaci v souřadnicích.
Víme, že každé lineární zobrazení lze vyjádřit jako matici. Abychom tak mohli učinit,
obecně nám v zápisu začnou figurovat 4 báze:
\begin{enumerate}
  \item báze určující vzorové souřadnice,
  \item transformovaná báze (kterou chceme transformovat),
  \item báze určující souřadnice obrazů,
  \item přetransformovaná báze (kterou jsme transformovali).
\end{enumerate}
To je poněkud matoucí, ale není na tom nic těžkého. Když tedy lineární zobrazení vyjádříme
jako matici, dostáváme:
\begin{equation*}
\mymatrix{L}\mycoord{b} = \mycoord{b'}
\end{equation*}
kde $\mycoord{b}$ je vektor báze (2) vyjádřený jako souřadnice báze (1), $\mycoord{b'}$ je
přetransformovaný vektor z báze (4) vyjádřený jako souřadnice báze (3) a sloupce matice
$\mymatrix{L}$ jsou obrazy vektorů báze (1) vyjádřené jako souřadnice báze (3) (viz. kapitola
XXX). Ztratili jste se? Zkuste si to ještě jednou, chce to jen trochu pečlivosti. Báze
(1) a (2) jsou obvykle stejné. Pak vektory $\mycoord{b}$ mají jednoduchý tvar 
$(0, \ldots, 0, 1, 0, \ldots, 0)^T$ a sloupce matice $\mymatrix{L}$ obsahují přímo obrazy
transformované báze.

Protože oba prostory musí mít stejnou dimenzi, matice $\mymatrix{L}$ musí být čtvercová.
Navíc sloupce tvoří bázi, tudíž musí být lineárně nezávislé. Podle velké věty algebry
je hodnost matice a hodnost transponované matice stejná, tudíž musí mít i lineárně
nezávislé řádky. Tedy, matice je regulární. Pro regulární matici existuje inverzní matice,
která nepříliš překvapivě odpovídá inverznímu zobrazení:
\begin{align*}
\mymatrix{L}\mycoord{v} &= \mycoord{w} \\
\mymatrix{L}^{-1}\mymatrix{L}\mycoord{v} &= \mymatrix{L}^{-1}\mycoord{w} \\
\mycoord{v} &= \mymatrix{L}^{-1}\mycoord{w} \\
\end{align*}
Matice $\mymatrix{L}^{-1}$ tedy odpovídá lineárnímu zobrazení, které každému obrazu
přiřadí jeho vzor, což je definice inverzního zobrazení.

Nyní si situaci ještě zjednodušme. Omezme se na transformaci z prostoru $\myspace{V}$
konečné dimenze do stejného prostoru $\mymap{L}: \myspace{V}\rightarrow\myspace{V}$.
Pokud báze (1), (2) a (3) vezmeme stejné, bude matice $\mymatrix{L}$ obsahovat přímo
přetransformované bázové vektory vyjádřené jako souřadnice původní báze.

Za těchto podmínek si můžeme položit otázku: jak se změní souřadnice vektoru $\myvec{v}$,
pokud přetransformujeme souřadnicový systém? Tato otázka je důležitá pro praxi, například
Newtonovo jablko padá k zemi s určitým vektorem rychlosti v daném časovém okamžiku. Jaké
bude mít vektor souřadnice, pokud například pootočíme souřadnicovou soustavu? Zkusme se
kouknout:
\begin{equation*}
\myvec{v} = \myscalar{v_1}\myvec{b_1} + \cdots + \myscalar{v_n}\myvec{b_n}
          = \myscalar{v'_1}\mymap{L}(\myvec{b_1}) + \cdots + \myscalar{v'_n}\mymap{L}(\myvec{b_n})
\end{equation*}
kde $\myscalar{v_i}$ jsou souřadnice vektoru před transformací, $\myscalar{v'_i}$ jsou souřadnice
vektoru po transformaci, $\myvec{b_i}$ jsou vektory báze před transformací a $\mymap{L}(\myvec{b_i})$
vektory báze po transformaci. Pokud toto zapíšeme jako souřadnice vůči bázi před transformací, získáme
\begin{equation*}
\mymatrix{I}\mycoord{v} = \mymatrix{L}\mycoord{v'}
\end{equation*}
Vektory báze před transformací vyjádřené jako souřadnice vůči sobě tvoří jednotkovou matici
$\mymatrix{I}$. Obrazy vektorů báze vyjádřené jako souřadnice vůči bázi před transformací
tvoří matici transformace $\mymatrix{L}$ (viz. XXX). Pokud tuto rovnici zleva vynásobíme
inverzní maticí $\mymatrix{L}^{-1}$ (matice transformace je regulární, proto inverzní
matice existuje) dostaneme
\begin{equation*}
\mymatrix{L}^{-1}\mycoord{v} = \mycoord{v'}
\end{equation*}
Souřadnice vektoru se tedy transformují \textbf{opačně}, než se transformuje báze.
Například pokud souřadnicovou soustavu otočíme o úhel $\alpha$ doprava, souřadnice vektoru
se změní tak, jakoby se vektor v původní souřadnicové soustavě otočil o stejný úhel doleva.
Pokud zvětším měřítko, souřadnice vektoru se změní, jakoby se měřítko vektoru zmenšilo (viz.
příklad XXX).

Tato vlastnost se nazývá \textit{kontravariance} a budeme se jí společně s jejím protějškem
\textit{kovariancí} zabývat v kapitole XXX.

\chapter{Duální vektorový prostor}

\section{Definice}

\noindent Pokud opustíme klidné vody vektorových prostorů, dostáváme se do bouřlivého oceánu
nepochopitlených úkazů. A hned prvním úkazem, o který si samouk nabije pusu, je \textit{duální
vektorový prostor}. Posuďte sami, něco takového najdete na Wikipedii:

\begin{definition}
Mějme vektorový prostor $\myspace{V}$ nad tělesem $\myspace{T}$. Pak \textbf{duální vektorový
prostor k prostoru $\myspace{V}$}, značený jako $\mydual{V}$, je množina všech lineárních
zobrazení $\mymap{\varphi}: \myspace{V}\rightarrow\myspace{T}$ doplněná o operace sčítání
a skalárního násobení:

\begin{enumerate}
  \item $(\mymap{\varphi} + \mymap{\psi})(\myvec{x}) = \mymap{\varphi}(\myvec{x}) + \mymap{\psi}(\myvec{x})$
  \item $(\myscalar{\alpha}\mymap{\varphi})(\myvec{x}) = \myscalar{\alpha}(\mymap{\varphi}(\myvec{x}))$
\end{enumerate}

\end{definition}

\noindent Jasné ne?

Ani se nemusíte pokoušet definici pochopit a už jste ztracení. Jaké lineární zobrazení z vektorového
prostoru do tělesa, když podle definice má jít o zobrazení z vektorového prostoru do vektorového
prostoru? Tady se totiž tiše zamlčel fakt, že těleso je možné chápat jako vektorový prostor sám
nad sebou, kdy operace vektorového sčítání a skalárního násobení přímo odpovídají sčítání a násobení
definovaného pro těleso. Je triviální si ověřit, že axiomy vektorového prostoru jsou v této situaci
vlastně shodné s odpovídajícími axiomy tělesa.

Dobře, nyní jsme si ujasnili formální stránku věci. Pojďme si zkusit vydedukovat, k čemu by něco
takového bylo. Pro tento účel nejdříve potřebujeme rozebrat význam prvků duálního prostoru.

\section{Lineární forma}

\noindent Lineární zobrazení do vlastního tělesa má svoji důležitost, a proto dostalo svůj vlastní
název \textbf{lineární forma}. Duální prostor je tedy množina všech lineárních forem nad příslušným
vektorovým prostorem. Lineární forma braná jako prvek duálního prostoru se obvykle nazývá 
\textbf{kovektor}.

Víme, že každé lineární zobrazení v konečných prostorech lze vyjádřit jako matici. Lineární forma
je zobrazení do tělesa, tedy prostoru s dimenzí 1. Její matice tedy bude mít pouze jednu řádku:
\begin{equation*}
\myscalar{K}=\mymap{L}(\myvec{x}) = \mycoord{\varphi}^T\mycoord{x} = \myscalar{\varphi_1}\myscalar{x_1} + \cdots + \myscalar{\varphi_n}\myscalar{x_n}
\end{equation*}
Pokud si zavzpomínáte na sladké časy na základní škole, možná si také vzpomenete, že rovnice, kterou
jsme dostali, se nápadně podobá rovnici plochy, kterou jsme se učili v základech geometrie. A nejedná
se o podobu náhodnou. Pomocí lineární formy můžeme zobecnit pojem \textbf{plocha} jako množinu vektorů,
pro které forma vrací stejnou hodnotu.

Všimli jste si? Nyní už pro definici plochy nepotřebujeme žádný geometrický význam. Plochu tak
lze nadefinovat i nad naprosto podivnými vektorovými prostory, nemusí to být jenom $\mathbb{R}^3$.

Ovšem tvrdit, že lineární forma určuje plochu, by bylo chybné. Forma určuje obecně nekonečně mnoho
ploch - pro různé prvky tělesa různé plochy.

\begin{example}\label{example:linforma1}Lineární formy v $\mathbb{R}^2$: pokud si vezmeme příklad
dvourozměrného prostoru, zde ``plocha`` je přímka. Linerání forma tedy určuje rovnoběžné přímky.
Příklad je na obrázku (K je hodnota vrstevnice).

\begin{center}
\includesvg[width=170pt]{linforma}
\end{center}

\noindent Červená šipka vyjadřuje normálu přímky. Pokud souřadnice normály vypíšeme do řádkového
vektoru, získáme ono maticové vyjádření lineární formy.

Ve standardní geometrii nás příliš nezajímala velikost normálového vektoru. Pokud nebyl nulový, určoval
přímku stejně bez ohledu na velikost. V počítačové grafice je například zcela běžné, že se normála
upravuje tak, aby měla jednotkovou velikost.

Ovšem v případě duálních prostorů nás velikost zajímá. Různé velikosti normálových vektorů odpovídají
různým lineárním formám, tedy různým prvkům duálního prostoru.

Geometricky nám velikost normály určuje ``hustotu`` přímek v jejím směru. Pokud je normála malá,
odstup přímek pro stejný rozdíl $K$ bude větší. Pokud je normála velká, odstup bude menší. Můžeme
na to koukat jako na vrstevnice plochy, která je vztyčená do třetí osy. Čím větší je normála, tím
je tato plocha strmější.

Anebo jinak, délka normály je velikost, o kolik plocha v jejím směru vzroste na jednotkovou
vzdálenost.

Analogie s vrstevnicemi je všeobecně používaná. V učebnicích se kovektory na obrázcích často kreslí
jako sekvence paralelních ploch - vrstevnice jakési pro nás nepředstavitelné čtyřrozměrné plochy.

\end{example}

\begin{example}\label{example:linforma2}Kreslení křivky. Jako další příklad si zkusme položit následující
úkol: máme dva body, mezi kterými chceme nakreslit křivku. V krajních bodech máme určený tečný vektor.
Jeho směr definuje tečnu křivky, jeho délka určuje, jak moc se křivka bude k tečně ``lepit``. Naším úkolem
je nalézt parametrické vyjádření křivky. Parametr si označíme jako $t$ a standardně ho necháme se pohybovat
v intervalu \textit{<0, 1>}. Situace je ukázaná na obrázku.

\begin{center}
\includesvg[width=200pt]{curve}
\end{center}

Už jsme si ukázali, že polynomy do určitého stupně tvoří vektorový prostor. Předpokládejme tedy, že
naše parametrické vyjádření bude polynom třetího stupně. Proč zrovna třetího? Máme 4 okrajové podmínky
(dva krajní body a dva tečné vektory), tudíž dává smysl použít prostor s dimenzí 4. Uvidíme později.

V principu vlastně chceme získat dva polynomy - jeden vyjadřující $x$ v závislosti na parametru $t$
a druhý vyjadřující $y$ v závislosti na parametru $t$. Následující odvození řeší souřadnici $x$, postup
pro druhou souřadnici je ekvivalentní.

Náš hledaný polynom tedy vypadá 
\begin{equation*}
p(t)=at^3 + bt^2 + ct + d
\end{equation*}
V bázi $\{t^3, t^2, t, 1\}$ jsou jeho souřadnice $(a, b, c, d)^T$. Abychom spočítali koeficienty
polynomu, musíme využít okrajové podmínky, které máme. Začněme prvním krajním bodem:
\begin{equation*}
x_0 = p(0) = 0a + 0b + 0c + d = \left(0, 0, 0, 1\right)\left(\begin{array}{c}
a\\
b\\
c\\
d
\end{array}\right)
\end{equation*}
Hodnotu polynomu pro $t=0$ jsme vyjádřili jako součin řádkového vektoru a sloupcového vektoru. Sloupcový
vektor jsou souřadnice vektoru v prostoru polynomů. Řádkový vektor tak určuje lineární formu. V tomto
případě nám lineární forma vrací hodnotu polynomu v $0$.\footnote{
  V XXX jsme si řekli, že každá matice určuje nějaké lineární zobrazení. Řádkový vektor je vlastně také
  matice, proto nám určuje lineární zobrazení. Jinak bychom samozřejmě mohli ověřit, zda zobrazení
  ``hodnota polynomu v bodě 0`` splňuje podmínky lineárního zobrazení. To je poměrně triviální úkol.
}

O kousek výše jsme říkali, že lineární forma zobecňuje pojem plocha. V tomto případě ``plochu`` tvoří
všechny polynomy, které v bodě $0$ mají stejnou hodnotu. A nás konkrétně zajímá ``plocha``, kdy tato
hodnota je $x_0$.

Zcela analogicky využijeme druhý krajní bod:
\begin{equation*}
x_1 = p(1) = a + b + c + d = \left(1, 1, 1, 1\right)\left(\begin{array}{c}
a\\
b\\
c\\
d
\end{array}\right)
\end{equation*}
Pro využití tečných vektorů musíme polynom nejdříve zderivovat:
\begin{equation*}
p'(t)=3at^2 + 2bt + c
\end{equation*}
a následně opět dosadit za parametr $t$ nulu a jedničku:
\begin{equation*}
\Delta x_0 = p'(0) = c = \left(0, 0, 1, 0\right)\left(\begin{array}{c}
a\\
b\\
c\\
d
\end{array}\right)
\end{equation*}
\begin{equation*}
\Delta x_1 = p'(1) = 3a + 2b + c = \left(3, 2, 1, 0\right)\left(\begin{array}{c}
a\\
b\\
c\\
d
\end{array}\right)
\end{equation*}
Opět jsme získali dvě lineární formy, které vrací hodnotu derivace polynomu v bodě $0$ a $1$.

Celkově nám všechny čtyři okrajové podmínky určují 4 ``plochy``. A my potřebujeme najít jejich
průsečík. Tím získáváme jednoduchou soustavu rovnic\footnote{
  Zde je vidět, proč jsme zvolili polynom třetího stupně. Máme 4 rovnice a abychom měli
  jednoznačné řešení, potřebujeme 4-rozměrný prostor. Pokud by měl méně rozměrů, okrajové
  podmínky by nemohly být nezávislé. Pokud by byl větší, polynomů by bylo nekonečně mnoho.
}
\begin{equation*}
\left(\begin{array}{cccc}
0 & 0 & 0 & 1\\
1 & 1 & 1 & 1\\
0 & 0 & 1 & 0\\
3 & 2 & 1 & 0
\end{array}\right)\left(\begin{array}{c}
a\\
b\\
c\\
d
\end{array}\right)=\left(\begin{array}{c}
x_0\\
x_1\\
\Delta x_0\\
\Delta x_1
\end{array}\right)
\end{equation*}
jejíž řešení je
\begin{equation*}
\begin{split}
a &= 2x_0 - 2x_1 + \Delta x_0 + \Delta x_1\\
b &= -3x_0 + 3x_1 - 2\Delta x_0 - \Delta x_1\\
c &= \Delta x_0\\
d &= x_0
\end{split}
\end{equation*}
Hurá, nyní známe koeficienty polynomu a můžeme si celkem snadno křivku mezi body nakreslit.

Zvídavý čtenář si může za domácí úkol vyzkoušet, že slavné Bezierovy kubiky jsou shodné s námi
nalezeným polynomem, pouze třetí a čtvrtá krajní podmínka je $3\Delta x_0$ a $3\Delta x_1$ (tzn.
křivky se k tečným vektorům ``lepí`` o něco agresivněji).

\end{example}

\noindent Pojďme se nyní zamyslet nad případem, kdy do lineární formy dosadíme nulový vektor. Již víme
(viz. XXX), že obrazem nulového vektoru je opět nulový vektor. V případě lineární formy nulový
prvek tělesa. Pokud tedy přijmeme geometrickou představu lineární formy jako ``vrstevnice``
nadřazené plochy z prostoru o jeden řád větší, pak tato plocha vždy \textbf{prochází počátkem
souřadnicového systému}: $\mymap{L}(\myvec{0}) = \myscalar{0}$, tedy vrstevnice pro $K = 0$ prochází
počátkem.

Ve fyzice se mluví o \textit{volných vektorech} - tzn. vektor má velikost a směr, ale není vázaný
ke konkrétnímu bodu v prostoru. Kovektory se chovají stejně - zajímá nás pouze prudkost a směr
sklonu plochy, ale ne, kde je nadřazená plocha v prostoru umístěná.

Tento význam je ve fyzice, často používaný. Typický kovektor je např. gradient, tzn. tečná plocha
funkce (hodnota funkce přidává rozměr navíc). Gradient se sice počítá pro konkrétní bod funkce,
jeho složky (parciální derivace v daném bodě) už ovšem tuto informaci dále nenesou.

Na závěr kapitoly proberme krajní případ: $\mymap{L}(\myvec{x}) = \myscalar{0}$. V geometrickém významu je
zřejmé, že tato rovnice neurčuje žádnou plochu ve vektorovém prostoru, nad kterým je forma definovaná,
protože normálový vektor je nulový. Nicméně jedná se o platnou lineární formu a její geometrický
význam jsou ``vrstevnice`` nadřazené plochy, která je rovnoběžná se ``základnou`` - například gradient
konstantní funkce nebo gradient funkce v lokálním extrému.

\subsection{Shrnutí}

Lineární forma tedy zobecňuje pojem plocha (rovina): rovnice $L(\mycoord{x}) = \myscalar{K}$ definuje
plochu i nad prostory, kde tento pojem nemá geometrickou představu.

Protože nás ale zajímá i délka normály, lineární forma určuje plochu v prostoru, který je o jeden
rozměr větší. Geometricky lineární forma definuje ``vrstevnice`` této plochy do prostoru, nad kterým
je forma definovaná. Tato plocha je určená jednoznačně, kromě jejího umístění.

\section{Vektorový prostor?}

\noindent Pozorný čtenář si možná všiml, že jsme v definici duálního vektorového prostoru poněkud
podváděli. Nadefinovali jsme duální prostor, ale nijak jsme neprokázali, že se jedná o vektorový
prostor. Pojďme to nyní rychle napravit.

Ve skutečnosti je to dost snadné. Sčítání a násobení skalárem je definované pomocí operací nad tělesem,
takže zcela přirozeně splňuje podmínky pro komutativitu, asociativitu, distribuci a násobení jednotkovým
prvkem:
\begin{equation*}
\begin{split}
\varphi(x) + \psi(x) &= \psi(x) + \varphi(x)\\
(\varphi(x) + \psi(x)) + \theta(x) &= \varphi(x) + (\psi(x) + \theta(x))\\
\alpha(\beta \varphi(x)) &= (\alpha\beta)\varphi(x)\\
\alpha(\varphi(x) + \psi(x)) &= \alpha\varphi(x) + \alpha\psi(x)\\
(\alpha + \beta)\varphi(x) &= \alpha\varphi(x) + \beta\varphi(x)\\
\myscalar{1}\varphi(x) &= \varphi(x)
\end{split}
\end{equation*}
Nyní potřebujeme nalézt nulový prvek tak, aby:
\begin{equation*}
\begin{split}
\myvec{0}(x) + \varphi(x) &= \varphi(x)
\end{split}
\end{equation*}
Takovou podmínku přirozeně splňuje lineární forma
\begin{equation*}
\begin{split}
\myvec{0}(x) &= \myscalar{0}
\end{split}
\end{equation*}
která, jak jsme si ukázali v předchozí kapitole, je krajním případem, a tudíž i snadno očekávatelná.
A s existujícím nulovým prvkem už není problém nalézt opačný prvek, jako lineární formu danou předpisem
\begin{equation*}
\begin{split}
-\varphi(x) &= \myscalar{-1}\varphi(x)
\end{split}
\end{equation*}

Nyní věříme, že duální prostor je vektorový prostor. Zkusme nyní zkonstruovat jeho bázi.

Mějme vektorový prostor $\myspace{V}$ s bází $\{\myvec{b_1}, \ldots, \myvec{b_n}\}$ a k němu duální
vektorový prostor $\mydual{V}$. Pro libovolný kovektor $\mymap{\varphi} \in \mydual{V}$ a libovolný
vektor $\myvec{x} = \myscalar{\alpha_1}\myvec{b_1} + \cdots + \myscalar{\alpha_n}\myvec{b_n} \in 
\myspace{V}$ můžeme (z~definice lineárního zobrazení) napsat:
\begin{equation*}
\mymap{\varphi}(\myvec{x}) = \mymap{\varphi}(\myscalar{\alpha_1}\myvec{b_1} + \cdots 
  + \myscalar{\alpha_n}\myvec{b_n}) = \myscalar{\alpha_1}\mymap{\varphi}(\myvec{b_1}) + \cdots
  + \myscalar{\alpha_n}\mymap{\varphi}(\myvec{b_n})
\end{equation*}
Zvolme nyní kovektory $\{\mymap{\epsilon_1}, \ldots, \mymap{\epsilon_n}\}$ takové, aby platilo
\begin{equation*}
\mymap{\epsilon_i}(\myvec{b_j}) = 
\begin{cases}
1 & i = j\\
0 & i \neq j
\end{cases}
\end{equation*}
a vyjádřeme (opět z definice lineárního zobrazení) jejich obrazy vektoru $\myvec{x}$
\begin{equation*}
\mymap{\epsilon_i}(\myvec{x}) = \myscalar{\alpha_1}\mymap{\epsilon_i}(\myvec{b_1}) + \cdots
  + \myscalar{\alpha_n}\mymap{\epsilon_i}(\myvec{b_n}) = \myscalar{\alpha_i}\mymap{\epsilon_i}(\myvec{b_i})
\end{equation*}
Nyní můžeme kovektory $\mymap{\epsilon_i}$ dosadit do vyjádření kovektoru $\mymap{\varphi}$ 
(nejdříve ke každému prvku součtu přinásobíme 1, následně otočíme pořadí součinu):
\begin{equation*}
\begin{split}
\mymap{\varphi}(\myvec{x}) &= \myscalar{\alpha_1}\mymap{\varphi}(\myvec{b_1}) + \cdots
  + \myscalar{\alpha_n}\mymap{\varphi}(\myvec{b_n}) \\
&= \myscalar{\alpha_1}\mymap{\varphi}(\myvec{b_1})\mymap{\epsilon_1}(\myvec{b_1}) + \cdots
  + \myscalar{\alpha_n}\mymap{\varphi}(\myvec{b_n})\mymap{\epsilon_n}(\myvec{b_n}) \\
&= \mymap{\varphi}(\myvec{b_1})\mymap{\epsilon_1}(\myvec{x}) + \cdots
  + \mymap{\varphi}(\myvec{b_n})\mymap{\epsilon_n}(\myvec{x})
\end{split}
\end{equation*}
Hodnoty $\mymap{\varphi}(\myvec{b_i})$ (dále značeno jako $\myscalar{\mu_i}$) jsou skaláry,
tedy libovolný kovektor můžeme vyjádřit jako lineární kombinaci kovektorů $\mymap{\epsilon_i}$.
Abychom je mohli považovat za bázi, zbývá dokázat, že jsou lineárně nezávislé. Předpokládejme tedy,
že existuje nenulová kombinace taková
\begin{equation*}
\myvec{0}(\myvec{x}) = \myscalar{\mu_1}\mymap{\epsilon_1}(\myvec{x}) + \cdots 
  + \myscalar{\mu_n}\mymap{\epsilon_n}(\myvec{x})
\end{equation*}
tedy alespoň jedno $\myscalar{\mu_i} \neq 0$. Pokud za vektor $\myvec{x}$ dosadíme vektor báze
$\myvec{b_i}$, dostaneme
\begin{equation*}
\myvec{0}(\myvec{b_i}) = \myscalar{\mu_i}\mymap{\epsilon_i}(\myvec{b_i}) = \myscalar{\mu_i} \neq 0
\end{equation*}
což je spor s původním předpokladem. Nenulová kombinace tedy neexistuje a množina kovektorů
$\{\mymap{\epsilon_1}, \ldots, \mymap{\epsilon_n}\}$ je lineárně nezávislá.

Zkonstruovali jsme tedy bázi $\{\mymap{\epsilon_1}, \ldots, \mymap{\epsilon_n}\}$ duálního prostoru.
Její velikost je $n$, tedy duální vektorový prostor \textbf{má stejnou dimenzi}, jako prostor, nad
kterým je definovaný.

Bázi, kterou jsme zkonstruovali, nazýváme \textbf{duální báze}. Aby nedošlo k mýlce, neplést se
spojením \textit{báze duálního prostoru}! Zatímco druhé označuje libovolnou bázi duálního
prostoru včetně té první, duální báze je jedna konkrétní báze duálního prostoru svázaná s
jednou konkrétní bází vektorového prostoru. Jinými slovy, pokud si zvolím bázi vektorového
prostoru, existuje k němu jedna konkrétní duální báze.

O kousek výše jsme libovolný kovektor vyjádřili jako
\begin{equation*}
\begin{split}
\mymap{\varphi}(\myvec{x}) &= \myscalar{\alpha_1}\mymap{\varphi}(\myvec{b_1}) + \cdots
  + \myscalar{\alpha_n}\mymap{\varphi}(\myvec{b_n}) \\
&= \myscalar{\alpha_1}\myscalar{\mu_1} + \cdots + \myscalar{\alpha_n}\myscalar{\mu_n}
\end{split}
\end{equation*}
Pokud vektor $\myvec{x}$ vyjádříme jako sloupcový vektor, získáme následující maticový součin
\begin{equation*}
\mymap{\varphi}(\myvec{x}) = \left(\begin{array}{ccc}
\myscalar{\mu_1} & \cdots & \myscalar{\mu_n}
\end{array}\right)\left(\begin{array}{c}
\myscalar{\alpha_1}\\
\vdots\\
\myscalar{\alpha_n}
\end{array}\right)
\end{equation*}
Kovektor zde působí jako \textbf{řádkový vektor}. Odtud také plyne, že v mnoha textech a učebnicích
se kovektor s řádkovým vektorem ztotožňuje.

\begin{example}\label{example:covector1}Ortonormální báze. Ortonormální báze je taková báze,
kdy pro skalární součin\footnote{
  O skalárním součinu jsme v tomto textu dosud nemluvili. Tak nějak se očekává, že ho čtenář
  zná.
} každé dvojice bázových vektorů platí:
\begin{equation*}
\myvec{b_i}\cdot\myvec{b_j} = 
\begin{cases}
1 & i = j\\
0 & i \neq j
\end{cases}
\end{equation*}
Z definice duální báze platí
\begin{equation*}
\mymap{\epsilon_i}(\myvec{b_i}) = 1 = \left(\epsilon_{i_1}, \ldots, \epsilon_{i_n}\right)
\left(\begin{array}{c}
b_{i_1} \\
\vdots \\
b_{i_n}\end{array}\right)
\end{equation*}
a z definice skalárního součinu platí:
\begin{equation*}
\left(b_{i_1}, \ldots, b_{i_n}\right)
\left(\begin{array}{c}
b_{i_1} \\
\vdots \\
b_{i_n}\end{array}\right) = 1
\end{equation*}
Je tedy zřejmé, že $\epsilon_{i_j} = b_{i_j}$. Jinými slovy, kovektory duální báze budou mít
zcela totožné souřadnice\footnote{
  Pozor! Nejedná se o stejné vektory. Vektory a kovektory ``žijí`` každý v jiném prostoru.
  Shodné budou pouze jejich souřadnice.
}.

Podívejme se na tuto situaci geometricky. Na následujícím obrázku je zobrazena ortonormální
báze v prostoru $\mathbb{R}^2$ (červeně) a naznačené ``vrstevnice`` kovektoru $\mymap{\epsilon_1}$:
\begin{center}
\includesvg[width=200pt]{covector_orthogonal}
\end{center}
Vrstevnice kovektoru $\mymap{\epsilon_1}$ o hodnotě 1 musí procházet vektorem $\myvec{b_1}$
a vrstevnice o hodnotě 0 musí procházet vektorem $\myvec{b_2}$. Zároveň z vlastností lineární
formy víme, že nultá vrstevnice musí procházet počátkem. Vrstevnice bázového kovektoru jsou
tedy rovnoběžné s druhou osou.

\medskip\noindent
Pozorování, že souřadnice ortonormální báze jsou shodné se souřadnicemi jejich duální báze,
je podstatně důležitější, než se na první pohled zdá. A zároveň vysvětluje další
z nevysvětlitelných problémů, na které samouk při studiu narazí.

Pokud se kouknete do libovolné učebnice, s klidným svědomím vám kreslí vektory i kovektory
jako šipečky nebo jako vrstevnice do jednoho obrázku. Což je dost podstatný nesoulad,
protože vektory a kovektory jsou prvky dvou zcela rozdílných prostorů.

Pozorování ortonormální báze tento problém vysvětluje. Plocha papíru obvykle symbolizuje
aritmetický vektor s ortonormální bází a geometrické vyjádření vektorů (ty ``šipečky``)
jsou jejich souřadnice vůči této bázi. Protože souřadnice ortonormální báze a její duální
báze jsou shodné, lze i kovektory kreslit jako ``šipečky`` na stejném papíru ve stejné
souřadnicové síti.

Jako bychom na papíru měli dvě průhledné vrstvy - jednu pro vektory, druhou pro kovektory.
Každá vrstva je oddělená (jiný prostor), ale my je vidíme dohromady jako jeden obrázek.

\end{example}

\begin{example}\label{example:covector2}Reciproční báze. Po všech útrapách s definováním
lineární formy a duálního prostoru jsme v předchozím příkladu dostali úplně stejný
řádkový vektor jako byl bázový sloupcový. Což je poněkud frustrující.

Naštěstí skutečná zábava s duální bází totiž začíná až v okamžiku, kdy báze vektorového prostoru
není ortonormální. Vezměme si případ báze $\myvec{b_1} = (2, 0)^T$ a $\myvec{b_2} = (1, 2)^T$
zobrazeném na následujícím obrázku
\begin{center}
\includesvg[width=200pt]{covector_general}
\end{center}
Číselně kovektor $\mymap{\epsilon_1}$ vychází takto\footnote{
  Povšimněte si, že bázové vektory zde vyjadřujeme jako souřadnice ortonormální báze. To je záměr,
  aby bylo něco vidět. Pokud bychom souřadnice psali vůči nim samotným, dostali bychom stejná čísla
  jako v předchozím příkladu a neměli bychom viditelný geometrický význam.
}
\begin{equation*}
\begin{split}
\left(\begin{array}{cc}\frac{1}{2} & -\frac{1}{4}\end{array}\right)\left(\begin{array}{c}2\\0\end{array}\right) &= 1\\
\left(\begin{array}{cc}\frac{1}{2} & -\frac{1}{4}\end{array}\right)\left(\begin{array}{c}1\\2\end{array}\right) &= 0
\end{split}
\end{equation*}
a kovektor $\mymap{\epsilon_2}$ takto
\begin{equation*}
\begin{split}
\left(\begin{array}{cc}0 & \frac{1}{2}\end{array}\right)\left(\begin{array}{c}2\\0\end{array}\right) &= 0\\
\left(\begin{array}{cc}0 & \frac{1}{2}\end{array}\right)\left(\begin{array}{c}1\\2\end{array}\right) &= 1
\end{split}
\end{equation*}
Pokud mluvíme o duální bázi v geometrickém významu, označuje se také někdy jako \textbf{reciproční báze}.
Vektor reciproční báze $\mymap{\epsilon_i}$ je vždy kolmý na všechny bázové vektory kromě $\myvec{b_i}$.

\end{example}
\end{document}

